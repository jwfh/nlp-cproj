Working with Context-free Grammars (BKL, Chapter 8; J&M, Chapters 13 and 14)
Though there are context-free morphophonological phenomena, context-free grammars are primarily used to both recognize and parse sentences relative to a syntactic grammar.
Parsing both recognizes and adds an internal structure to a sentence; in the case of syntactic parsing, this structure is the hierarchical constituent phrase-structure of the sentence, cf., Part-of-Speech (POS) tagging.
As mentioned previously, this phrase-structure parse tree is useful as a model of the semantics of a sentence.
Parsing a sentence S with n words relative to a grammar G can be seen as a search over all possible parse trees that can be generated by grammar G with the goal of finding all parse trees whose leaves are labelled with exactly the words in S in an order that (depending on the language, is either exactly or is consistent with) that in S.
Need all possible parse trees to access all possible meanings.
Parsing algorithms can be classified using two dimensions:
Type of search
Dictated by the source of constraints on the search.
Top-down (goal-directed) search is constrained by the parse trees consistent with the given grammar G; bottom-up (data-directed) search is constrained by the words in given sentence S and their order within that sentence.
Top-down search will only consider parse trees consistent with G, but may end up generating parse trees that are not consistent with S; bottom-up search will only consider parse-tree structure consistent with S, but may end up generating local parse-tree sub-structures that are not consistent with G.
Example #1 (see figure): Example of parse trees generated by top-down search for the sentence "Book that flight" (J&M, Figure 13.3).
Example #2 (see figure): Example of parse trees generated by bottom-up search for the sentence "Book that flight" (J&M, Figure 13.4).
Mechanisms of search
Types of mechanisms used in parsing algorithm to implement (and possibly speed up) search.
Naive implementations of search use backtracking, which is simple and space-efficient but runs the risk of generating parse tree substructures multiple times.
Smarter implementations of search use dynamic programming, which remembers intermediate parse tree substructures so they are not generated multiple times but can be complex and much more costly wrt space.
Though some algorithms implement the generation of one valid parse for a given sentence much quicker than others, the generation of all valid search trees (which is required in the simplest human-guided schemes for resolving sentence ambiguities) for all parsing algorithms is in the worst case at least the number of valid parse trees for the given sentence S relative to the given grammar G.
There are natural grammars for which this is quantity is exponential in the number of words in the given sentence (BKL, p. 317; Carpenter (2003), Section 9.4.2).
Implementing deterministic context-free parsing
Recursive-descent parsing [top-down / backtracking] (BKL, pp. 303-304; Carpenter (2003), Section 9.4.4)
Grows a parse tree downward, starting from a tree consisting of a single node labelled with grammar-sentence / start symbol S and, at each point, generating daughter parse trees by expanding leftmost leaf-node labelled with a non-terminal in all possible ways that this non-terminal can be expanded by the grammar.
Note that leftmost non-terminal leaf-node expansion corresponds to depth-first parse tree generation.
Every time a parse tree is created with n leaves, it is checked to see if these leaves (if terminal) or direct expansion of these leaves into words (if non-terminal) results in the given sentence. If so, that parse tree is valid for the sentence. Otherwise, backtracking is invoked to try another possible tree.
Example #3 (see figure): Example of recursive-descent parse for for the sentence "The dog saw the man in the park" (BKL, Figure 8.4).
In the worst case, this algorithm requires O(|#DT(G,n)||LDT(G,n)|) time and O(n|LDT(G,n)) space to generate either one or all valid parses of a given sentence, where |#DT(G,n)|$ is the number of parse trees with n leaves consistent with grammar G and |LDT(G,n)| is the maximum possible size of a parse tree with n leaves that is consistent with G.
Though simple and having a low space complexity, this algorithm has all the problems associated with the top-down parsing approach. The depth-first search version described here has the additional problem that left-recursive rules, e.g., NP -> NP PP, can make the algorithm go into an infinite loop.
This last problem can be fixed by either removing rules of this form (conversion to Greibach Normal Form (HU79, Section 4.6)) or pre-processing the grammar to extract constraints that can be used in a hybrid top-down / bottom-up manner (left-corner parsing (BKL, 306-307; Carroll (2003), Section 12.3.2)).
Shift-reduce parsing [bottom-up] (BKL, pp. 304-306)
Grows a parse tree upwards from the left-hand side of a sentence using a stack initialized to empty and two operators:
Shift: Place the next word to be processed in the given sentence on the stack.
Reduce: Replace the topmost k, k >= 1, entities y1, y2, ..., yk on the stack with the higher-level non-terminal X if there is a rule of the form X -> y1 y2 ... yk in the given grammar G.
The process terminates when no shift or reduce operations can be applied, and recognizes the given sentence as valid relative to G if only the grammar sentence / start symbol S is all that remains on the stack.

Example #4 (see figure PDF): Example of shift-reduce parse for for the sentence "The dog saw the man in the park" (BKL, Figure 8.5).
In the worst case, this algorithm requires O(|LDT(G,n)|) time and space to generate one valid parse of a given sentence.
Though simple and having a low space complexity, this algorithm has all the problems associated with the bottom-up parsing approach. The simple version described above has the additional problem that it is incorrect, in that it may fail to find a valid parse even when one exists.
This last problem occurs because there may a choice of operators to apply at any point (some but possibly not all leading to alternate valid parses caused by ambiguity).
These problems can be resolved by adding backtracking, though this may dramatically raise the time and space complexity.
For unambiguous well-structured grammars, choosing operators using both stack and bounded lookahead in the portion of the given sentence yet to be processed may suffice to guarantee correctness; indeed, it is this strategy that is used in many parsers for computer programming languages!
