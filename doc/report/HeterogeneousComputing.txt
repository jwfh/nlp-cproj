The usage of the CPU as a generalized process, and the GPU as an
accelerator to the CPU has been a common practice just before
and continuing after 2010. This configuration is what's
considered as general-purpose computing on a GPU. This
configuration offers significant performance benefits in a
system, particularly in data-parallel, and computationally
heavy process. Heterogeneous system architecture is used to
leverage the value of each unique device, The CPU being well
designed for tasks were latency is critical, while the GPU is
the choice processor in throughput-oriented tasks. This creates
two different classifications; a latency compute unit (LUT)
being a general CPU, and a throughput compute unit being a
general GPU. Both processing units are capable of performing
 the same calculations or tasks, however the different
 architectures have different strengths and weaknesses. The
 strengths and weaknesses of each processor boils down to their
 internal structure. CPUs are composed of a few large, flexible,
 and fast clocked cores, while GPUs are built using thousands of
 cores that are both smaller and slower, but are highly
 parallelized. In addition to performance, energy efficiency
 is also an important factor while GPUs have considerably
 greater computational power than CPU's, the have approximately
 the same energy cost. For example, when comparing the Intel
 Xeon E7 CPU, 150 watts delivers around 100GFlops/s, while a
 small increase of energy to 250 Watts in the NVIDIA GK110
 provides 1.3 TFlops/s. At the time of writing of this article
 in 2015, these were both state of the art processors.
