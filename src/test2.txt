The usage of the CPU as a generalized process, and the GPU as an accelerator to the CPU has been a common practice just before and continuing after 2010 [1]. This configuration is what’s considered as general-purpose computing on a GPU. This configuration offers significant performance benefits in a system, particularly in data-parallel, and computationally heavy process [2]. Heterogeneous system architecture is used to leverage the value of each unique device, The CPU being well designed for tasks were latency is critical, while the GPU is the choice processor in throughput-oriented tasks. This creates two different classifications; a latency compute unit (LUT) being a general CPU, and a throughput compute unit being a general GPU [3]. Both processing units are capable of performing the same calculations or tasks, however the different architectures have different strengths and weaknesses [1]. The strengths and weaknesses of each processor boils down to their internal structure. CPUs are composed of a few large, flexible, and fast clocked cores, while GPU’s are built using thousands of cores that are both smaller and slower, but are highly parallelized [1]. In addition to performance, energy efficiency is also an important factor while GPUs have considerably greater computational power than CPU’s, the have approximately the same energy cost. For example, when comparing the Intel Xeon E7 CPU, 150 watts delivers around 100GFlops/s, while a small increase of energy to 250 Watts in the NVIDIA GK110 provides 1.3 TFlops/s. At the time of writing of this article in 2015, these were both state of the art processors. 